{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f788e71-9c33-49c3-a8dc-59947074d920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:01.525995Z",
     "start_time": "2025-03-07T23:08:01.518742Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42da3359",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:01.699735Z",
     "start_time": "2025-03-07T23:08:01.694440Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using GPU?\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e36fc-9d49-40e3-b040-1660f1688ea4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:01.775799Z",
     "start_time": "2025-03-07T23:08:01.702547Z"
    }
   },
   "outputs": [],
   "source": [
    "music = pd.read_csv(\"music.csv\")\n",
    "music.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0984a-acea-458a-812f-a1918597b8ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:01.790183Z",
     "start_time": "2025-03-07T23:08:01.776812Z"
    }
   },
   "outputs": [],
   "source": [
    "print(music.shape[0])\n",
    "music.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625e8639-862d-457a-a6e5-88024c9cd876",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4689b238-9a4d-4b06-809e-d1d43ab1d6fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:01.824280Z",
     "start_time": "2025-03-07T23:08:01.792203Z"
    }
   },
   "outputs": [],
   "source": [
    "print(music[music.isna().any(axis=1)].shape[0])\n",
    "music[music.isna().any(axis=1)].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ff200-ba9c-4d0c-b87f-cacdd6552339",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:01.857452Z",
     "start_time": "2025-03-07T23:08:01.826572Z"
    }
   },
   "outputs": [],
   "source": [
    "music = music.drop(columns=['artist_mbtags','song.hotttnesss'])\n",
    "music[music.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36763c-24db-466e-a9c4-b11f68c520d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:01.943569Z",
     "start_time": "2025-03-07T23:08:01.859464Z"
    }
   },
   "outputs": [],
   "source": [
    "music = music.dropna()\n",
    "music[music.isna().any(axis=1)]\n",
    "print(music.shape[0])\n",
    "music.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08defb90-8259-406b-b453-cbe722f359f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:01.959510Z",
     "start_time": "2025-03-07T23:08:01.946579Z"
    }
   },
   "outputs": [],
   "source": [
    "music.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536fdd80-db9e-4589-91be-8db27bcc0745",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3fc7ee-da9b-4665-a7e9-55983aefb9a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:01.969278Z",
     "start_time": "2025-03-07T23:08:01.962596Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_cols = ['artist.id', 'artist.name', 'location', 'release.id', 'release.name', \n",
    "             'similar', 'song.id', 'title', 'terms']\n",
    "music_numeric = music.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d71f18-eb56-45e8-a68a-7e4c8e5e860f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:01.993795Z",
     "start_time": "2025-03-07T23:08:01.982801Z"
    }
   },
   "outputs": [],
   "source": [
    "# encode terms to numeric\n",
    "label_encoder = LabelEncoder()\n",
    "music_numeric['genre'] = label_encoder.fit_transform(music_numeric['genre'])\n",
    "\n",
    "X = music_numeric.drop(columns=['genre'])\n",
    "y = music_numeric['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6879fa0c-cd6e-4bd9-b83d-88708d174385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:03.791596Z",
     "start_time": "2025-03-07T23:08:02.167689Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Fit the transformer only on the training set \n",
    "transformer = StandardScaler().fit(X_train)\n",
    "X_train_norm = pd.DataFrame(transformer.transform(X_train), columns = X_train.columns)\n",
    "\n",
    "# Apply the same transformation to the testing set\n",
    "X_test_norm = transformer.transform(X_test)\n",
    "\n",
    "# Range of alphas (follow log: 0.001 - 1000 normally)\n",
    "alphas = np.logspace(-3, 3, 100)\n",
    "\n",
    "# Lasso Cross-validation, 10 folds\n",
    "lassocv = LassoCV(cv=10, \n",
    "                  alphas=alphas, \n",
    "                  max_iter=10000, \n",
    "                  tol=1e-4, \n",
    "                  random_state=404)\n",
    "lassocv.fit(X_train_norm, y_train)\n",
    "\n",
    "# mean MSE across folds for each alpha\n",
    "mse_mean = np.mean(lassocv.mse_path_, axis=1)\n",
    "\n",
    "# MSE versus alphas\n",
    "plt.plot(lassocv.alphas_, mse_mean, linestyle='--')\n",
    "plt.scatter(lassocv.alpha_, mse_mean[np.argmin(mse_mean)], label='optimal alpha')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('MSE vs Alpha')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Optimal alpha (Lasso):', lassocv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a9757-225b-455f-a09a-c7567b5b2e20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:03.808093Z",
     "start_time": "2025-03-07T23:08:03.792692Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lasso Coefficients\n",
    "lasso_coefficients = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'coefficient': lassocv.coef_\n",
    "})\n",
    "\n",
    "nonzero_features = lasso_coefficients[lasso_coefficients['coefficient'] != 0]\n",
    "nonzero_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa36fd0",
   "metadata": {},
   "source": [
    "### Logistic Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feadee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:11.299085Z",
     "start_time": "2025-03-07T23:08:03.812112Z"
    }
   },
   "outputs": [],
   "source": [
    "select_col = lasso_coefficients[lasso_coefficients['coefficient'] != 0]['feature'].to_list()\n",
    "X = music_numeric[select_col]\n",
    "y = music_numeric['terms']\n",
    "\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)\n",
    "\n",
    "transformer = StandardScaler().fit(X_train)\n",
    "X_train_norm = pd.DataFrame(transformer.transform(X_train), columns = X_train.columns)\n",
    "\n",
    "# Apply the same transformation to the testing set\n",
    "X_test_norm = transformer.transform(X_test)\n",
    "\n",
    "log_reg = LogisticRegression(random_state=0, max_iter=1000).fit(X_train_norm, y_train)\n",
    "log_reg.predict_proba(X_test_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df87bdc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b3c025",
   "metadata": {},
   "source": [
    "#### Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f941e7e0",
   "metadata": {},
   "source": [
    "##### Graph Structure\n",
    "\n",
    "<div>\n",
    "<img src=\"media/graph.jpg\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc1e76a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:11.329106Z",
     "start_time": "2025-03-07T23:08:11.303393Z"
    }
   },
   "outputs": [],
   "source": [
    "# These will be the three key identifiers\n",
    "song_id_map = {sid: i for i, sid in enumerate(list(music['song.id']))}                  # There can only be one song\n",
    "artist_id_map = {aid: i for i, aid in enumerate(list(music['artist.id'].unique()))}     # They can be under the same artist\n",
    "release_id_map = {aid: i for i, aid in enumerate(list(music['release.id'].unique()))}   # They can be under the same release\n",
    "\n",
    "# Tags\n",
    "tag_id_map = {tid: i for i, tid in enumerate(list(music['terms'].unique()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8d9be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:21.071371Z",
     "start_time": "2025-03-07T23:08:11.330112Z"
    }
   },
   "outputs": [],
   "source": [
    "### SONG NODE ###\n",
    "song_features = ['bars_confidence', 'bars_start', 'beats_confidence', 'beats_start',\n",
    "    'duration', 'end_of_fade_in', 'key', 'key_confidence', 'loudness',\n",
    "    'mode', 'mode_confidence', 'start_of_fade_out', 'tatums_confidence',\n",
    "    'tatums_start', 'tempo', 'time_signature', 'time_signature_confidence']\n",
    "\n",
    "num_songs = len(music['song.id'])\n",
    "num_song_feats = len(song_features)\n",
    "song_x = np.zeros((num_songs, num_song_feats), dtype=np.float32)\n",
    "\n",
    "for i, sid in enumerate(music['song.id']):\n",
    "    row = music.loc[music['song.id'] == sid].iloc[0]\n",
    "    song_x[i] = row[song_features].values\n",
    "    \n",
    "song_x = torch.tensor(song_x, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd825d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:26.215805Z",
     "start_time": "2025-03-07T23:08:21.073391Z"
    }
   },
   "outputs": [],
   "source": [
    "### ARTIST NODE ###\n",
    "artist_features = ['artist.hotttnesss', 'artist_mbtags_count', 'familiarity']\n",
    "artist_ids = music['artist.id'].unique()\n",
    "num_artists = len(artist_ids)\n",
    "artist_x = np.zeros((num_artists, len(artist_features)), dtype=np.float32)\n",
    "\n",
    "for i, aid in enumerate(artist_ids):\n",
    "    rows = music[music['artist.id'] == aid].iloc[0]\n",
    "    artist_x[i] = rows[artist_features].values\n",
    "\n",
    "artist_x = torch.tensor(artist_x, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e5fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:26.230371Z",
     "start_time": "2025-03-07T23:08:26.219122Z"
    }
   },
   "outputs": [],
   "source": [
    "### RELEASE NODE ###\n",
    "num_releases = len(music['release.id'].unique())\n",
    "release_x = torch.zeros((num_releases, 1), dtype=torch.float32)\n",
    "\n",
    "num_tags = len(music['terms'].unique())\n",
    "tag_x = torch.zeros((num_tags, 1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa96b05c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:26.435983Z",
     "start_time": "2025-03-07T23:08:26.234821Z"
    }
   },
   "outputs": [],
   "source": [
    "### BUILD EDGES ###\n",
    "\n",
    "# First row is source idx (song)\n",
    "# Second row is the destination (artist)\n",
    "\n",
    "# Song -----> Artist\n",
    "song_src = []\n",
    "artist_dst = []\n",
    "\n",
    "for idx, row in music.iterrows():\n",
    "    s_id = row['song.id']\n",
    "    a_id = row['artist.id']\n",
    "    s_idx = song_id_map[s_id]\n",
    "    a_idx = artist_id_map[a_id]\n",
    "\n",
    "    song_src.append(s_idx)\n",
    "    artist_dst.append(a_idx)\n",
    "\n",
    "song_artist_edge_index = torch.tensor([song_src, artist_dst], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900b3131",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:26.626432Z",
     "start_time": "2025-03-07T23:08:26.437145Z"
    }
   },
   "outputs": [],
   "source": [
    "# Song -----> Release\n",
    "song_src = []\n",
    "release_dst = []\n",
    "\n",
    "for idx, row in music.iterrows():\n",
    "    s_id = row['song.id']\n",
    "    r_id = row['release.id'] \n",
    "    s_idx = song_id_map[s_id]\n",
    "    r_idx = release_id_map[r_id]\n",
    "    song_src.append(s_idx)\n",
    "    release_dst.append(r_idx)\n",
    "\n",
    "song_release_edge_index = torch.tensor([song_src, release_dst], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed1a9af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:26.630421Z",
     "start_time": "2025-03-07T23:08:26.627455Z"
    }
   },
   "outputs": [],
   "source": [
    "# Song -----> Tag\n",
    "\n",
    "song_src = []\n",
    "tag_dst = []\n",
    "song_tag_weights = []\n",
    "\n",
    "for idx, row in music.iterrows():\n",
    "    s_id = row['song.id']\n",
    "    s_idx = song_id_map[s_id]\n",
    "    \n",
    "    tag = row['terms']\n",
    "    freq = row['terms_freq']\n",
    "\n",
    "    t_idx = tag_id_map[tag]\n",
    "    \n",
    "    song_src.append(s_idx)\n",
    "    tag_dst.append(t_idx)\n",
    "    song_tag_weights.append(freq)\n",
    "\n",
    "song_tag_edge_index = torch.tensor([song_src, tag_dst], dtype=torch.long)\n",
    "song_tag_edge_attr = torch.tensor(song_tag_weights, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ecdd20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T23:08:26.845923Z",
     "start_time": "2025-03-07T23:08:26.839042Z"
    }
   },
   "outputs": [],
   "source": [
    "# Put in HeteroData\n",
    "data = HeteroData()\n",
    "\n",
    "# Assign node features\n",
    "data['song'].x = song_x\n",
    "data['artist'].x = artist_x\n",
    "data['release'].x = release_x\n",
    "data['tag'].x = tag_x\n",
    "\n",
    "# Assign edges\n",
    "data['song', 'performed_by', 'artist'].edge_index = song_artist_edge_index\n",
    "data['song', 'released_on', 'release'].edge_index = song_release_edge_index\n",
    "data['song', 'has_tag', 'tag'].edge_index = song_tag_edge_index\n",
    "data['song', 'has_tag', 'tag'].edge_attr = song_tag_edge_attr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce783249",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
